{
 "metadata": {
  "name": "",
  "signature": "sha256:a1cb75bcff4b5bc58d3a5d825405cb47cca57c05093d947e55a913635aeebe0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Scraping"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we'll download the HTML files containing the data, which, of course, have inconsistently formatted URLs. The following could have been done a little more efficiently in terms of processing time. \n",
      "\n",
      "If you want to run this yourself, you'll have to change the <tt>working_folder</tt> variable to the path of an existing directory on your machine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "working_folder = 'c:/py/sunshine/htm'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "\n",
      "urls = []\n",
      "for i in range(1997, 2010):\n",
      "  urls.append((str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/%s/univer%s.html' % (str(i), str(i)[2:])))\n",
      "  urls.append((str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/%d/universi.html' % i))\n",
      "  urls.append((str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/%d/univers.html' % i))\n",
      "urls.append(('2010-0','http://www.fin.gov.on.ca/en/publications/salarydisclosure/2010/univer10a.html'))\n",
      "urls.append(('2010-1','http://www.fin.gov.on.ca/en/publications/salarydisclosure/2010/univer10b.html'))\n",
      "urls.append(('2011-0','http://www.fin.gov.on.ca/en/publications/salarydisclosure/2011/univer11a.html'))\n",
      "urls.append(('2011-1','http://www.fin.gov.on.ca/en/publications/salarydisclosure/2011/univer11b.html'))\n",
      "urls.append(('2001','http://www.fin.gov.on.ca/en/publications/salarydisclosure/2001/unive01.html'))\n",
      "for i in range(3):\n",
      "  urls.append(('2012-'+str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=%d&organization=universities&year=2012' % i))\n",
      "for i in range(4):\n",
      "  urls.append(('2013-'+str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=%d&organization=universities&year=2013' % i))\n",
      "  urls.append(('2014-'+str(i),'http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs-tbs.php?pageNum_tbs=%d&organization=universities&year=2014' % i))\n",
      "for url in urls:\n",
      "  try:\n",
      "    f_in = urllib2.urlopen(url[1])\n",
      "    print('downloading %s...' % url[1])\n",
      "    text = f_in.read()\n",
      "    with open('%s/%s.htm' % (working_folder,url[0]), 'w') as f_out:\n",
      "      f_out.write(text)\n",
      "  except:\n",
      "    #print('didn\\'t find %s.' % url[1])\n",
      "    pass\n",
      "print('finished downloading.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/1997/univers.html...\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/1998/univer98.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/1999/universi.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2000/univer00.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2002/univer02.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2003/univer03.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2004/univer04.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2005/univer05.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2006/univer06.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2007/univer07.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2008/univer08.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2009/univer09.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2010/univer10a.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2010/univer10b.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2011/univer11a.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2011/univer11b.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/2001/unive01.html..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=0&organization=universities&year=2012..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=1&organization=universities&year=2012..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=2&organization=universities&year=2012..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=0&organization=universities&year=2013..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs-tbs.php?pageNum_tbs=0&organization=universities&year=2014..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=1&organization=universities&year=2013..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs-tbs.php?pageNum_tbs=1&organization=universities&year=2014..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=2&organization=universities&year=2013..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs-tbs.php?pageNum_tbs=2&organization=universities&year=2014..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs.php?pageNum_pssd=3&organization=universities&year=2013..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "downloading http://www.fin.gov.on.ca/en/publications/salarydisclosure/pssd/orgs-tbs.php?pageNum_tbs=3&organization=universities&year=2014..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "finished downloading."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All right, time to parse with regular expressions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, glob\n",
      "\n",
      "file_path_list = glob.glob('%s/*.htm' % working_folder)\n",
      "pat = {}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These patterns were obtained by taking from each HTML file a snippet of the kind we want to find and calling <tt>re.sub(r'\\s+', '\\\\s+', snippet_string)</tt>. I think a couple of them could have been subsumed by a common generalization,\n",
      "but there you have it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pat1997 = r'<TR\\s+VALIGN=\"bottom\">\\s+<TD\\s+ALIGN=\"left\">\\s+UNIVERSITIES</TD>\\s+<TD\\s+ALIGN=\"left\">\\s+(.+)</TD>\\s+<TD\\s+ALIGN=\"left\">\\s+(.+)</TD>\\s+<TD\\s+ALIGN=\"left\">\\s+(.+)</TD>\\s+<TD\\s+ALIGN=\"left\">\\s+(.+)</TD>\\s+<TD\\s+ALIGN=\"right\">\\s+(.+)\\s+</TD>\\s+<TD\\s+ALIGN=\"right\">\\s+(.+)\\s+</TD>\\s+</TR>'\n",
      "pat1998 = r'<TR\\s+VALIGN=\"TOP\">\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD\\s+ALIGN=\"RIGHT\">(.+)</TD>\\s+<TD\\s+ALIGN=\"RIGHT\">(.+)</TD>\\s+</TR>'\n",
      "pat1999 = r'<TR>\\s*<TD>\\s*(.*)\\s*</TD>\\s*<TD>\\s*(.*)\\s*</TD>\\s*<TD>\\s*(.*)\\s*C\\s*</TD>\\s*<TD>\\s*(.*)\\s*</TD>\\s*<TD\\s*align=\"right\">(.*)\\s*</TD>\\s*<TD\\s*align=\"right\">(.*)\\s*</TD>\\s*</TR>'\n",
      "pat2000 = r'<TR>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD\\s+align=\"right\">(.+)</TD>\\s+<TD\\s+align=\"right\">(.+)</TD>\\s+</TR>'\n",
      "pat2002 = r'<TR>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD>(.+)</TD>\\s+<TD\\s+ALIGN=\"right\">(.+)</TD>\\s+<TD\\s+ALIGN=\"right\">(.+)</TD>\\s*</TR>'\n",
      "pat2010 = r'<tr>\\s+.+\"top\">(.*)</td>\\s+.+top\">(.+)</td>\\s+.+top\">(.+)</td>\\s+.+top\">(.+)</td>\\s+.+top\">(.+)</td>\\s+.+top\">(.+)</td>\\s+'\n",
      "pat2012 = r'<tr>\\s+<td\\s+colspan=\"2\"\\s+align=\"left\"\\s+valign=\"top\"><span\\s+lang=\"en\">(.+)</span>\\s+</td>\\s+<td\\s+align=\"left\"\\s+valign=\"top\">(.+)</td>\\s+<td\\s+colspan=\"2\"\\s+align=\"left\"\\s+valign=\"top\">(.+)</td>\\s+<td\\s+align=\"left\"\\s+valign=\"top\"><span\\s+lang=\"en\">\\s+(.+)</span></td>\\s+<td\\s+align=\"right\"\\s+valign=\"top\">(.+)</td>\\s+<td\\s+colspan=\"2\"\\s+align=\"right\"\\s+valign=\"top\">(.+)</td>\\s+</tr>'\n",
      "\n",
      "pats = [pat1997, pat1998, pat1999, pat2000, pat2002, pat2010, pat2012]\n",
      "\n",
      "htmstr = {}\n",
      "df_dict = {}\n",
      "\n",
      "for path in file_path_list:\n",
      "    m = re.search(r'([^\\\\]+?)\\.htm',path)\n",
      "    with open(path) as f:\n",
      "        print('parsing %s...' % m.group(0))\n",
      "        htmstr[m.group(1)] = f.read()\n",
      "        for pat in pats:\n",
      "            x = re.findall(pat, htmstr[m.group(1)])\n",
      "            if len(x) > 0:\n",
      "                df_dict[m.group(1)] = DataFrame(x)\n",
      "                df_dict[m.group(1)].columns = ['employer','surname','given_name','position','salary','benefits']\n",
      "                df_dict[m.group(1)]['year'] = int(m.group(1)[:4])\n",
      "                break\n",
      "        if m.group(1) not in df_dict.keys(): print('couldn\\'t find a match for %s' % m.group(0))\n",
      "print('done parsing.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "parsing 1997.htm...\n",
        "parsing 1998.htm...\n",
        "parsing 1999.htm...\n",
        "parsing 2000.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2001.htm...\n",
        "parsing 2002.htm...\n",
        "parsing 2003.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2004.htm...\n",
        "parsing 2005.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2006.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2007.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2008.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2009.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2010-0.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2010-1.htm...\n",
        "parsing 2011-0.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2011-1.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2012-0.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2012-1.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2012-2.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2013-0.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2013-1.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2013-2.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2013-3.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2014-0.htm...\n",
        "parsing 2014-1.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2014-2.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "parsing 2014-3.htm..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "done parsing."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Put it together into a DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.concat([df_dict[k] for k in df_dict.keys()])\n",
      "df.index = range(len(df))\n",
      "print(df.ix[::1000].head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           employer      surname       given_name  \\\n",
        "0             University of Toronto           YI  BYEONG&ndash;UK   \n",
        "1000         University of Waterloo  VANDERBURGH        IAN W. T.   \n",
        "2000  University of Western Ontario     SIQUEIRA           WALTER   \n",
        "3000     Wilfrid Laurier University       MULLOY           DARREN   \n",
        "4000                York University       MADHOK            ANOOP   \n",
        "\n",
        "                     position       salary benefits  year  \n",
        "0     Professor of Philosophy  $131,951.48  $306.84  2012  \n",
        "1000                 Lecturer  $131,519.56  $682.92  2012  \n",
        "2000      Assistant Professor  $126,377.42   $95.40  2012  \n",
        "3000                  Faculty  $108,559.01  $395.28  2012  \n",
        "4000                Professor  $273,480.73  $489.84  2012  \n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Cleaning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bit of a mess. Time to clean. First, let's turn the salary and benefits figures into floats so we can do math with them later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean_money(s):\n",
      "    m = re.search('\\$.+\\.\\d+', s)\n",
      "    if m:\n",
      "        return float(m.group(0).replace('$','').replace(',',''))\n",
      "    else:\n",
      "        return s\n",
      "df.salary = df.salary.apply(clean_money)\n",
      "df.benefits = df.benefits.apply(clean_money)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df[['salary','benefits']].ix[::1000].head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "         salary  benefits\n",
        "0     131951.48    306.84\n",
        "1000  131519.56    682.92\n",
        "2000  126377.42     95.40\n",
        "3000  108559.01    395.28\n",
        "4000  273480.73    489.84\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the text fields, we'll capitalize everything and remove all accents."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in ['employer','surname','given_name','position']:\n",
      "    df[c] = df[c].str.upper()\n",
      "\n",
      "print df.ix[::1000].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           employer      surname       given_name  \\\n",
        "0             UNIVERSITY OF TORONTO           YI  BYEONG&NDASH;UK   \n",
        "1000         UNIVERSITY OF WATERLOO  VANDERBURGH        IAN W. T.   \n",
        "2000  UNIVERSITY OF WESTERN ONTARIO     SIQUEIRA           WALTER   \n",
        "3000     WILFRID LAURIER UNIVERSITY       MULLOY           DARREN   \n",
        "4000                YORK UNIVERSITY       MADHOK            ANOOP   \n",
        "\n",
        "                     position     salary  benefits  year  \n",
        "0     PROFESSOR OF PHILOSOPHY  131951.48    306.84  2012  \n",
        "1000                 LECTURER  131519.56    682.92  2012  \n",
        "2000      ASSISTANT PROFESSOR  126377.42     95.40  2012  \n",
        "3000                  FACULTY  108559.01    395.28  2012  \n",
        "4000                PROFESSOR  273480.73    489.84  2012  \n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def deabbreviate(s):\n",
      "    if 'ABBR' not in s:\n",
      "        return s\n",
      "    else:\n",
      "        s = s.replace('<ABBR TITLE=\"','')\n",
      "        s = re.sub(r'\">.*?</ABBR>',' ',s)\n",
      "        s = re.sub('[^A-Z /]','',s)\n",
      "        s = s.replace('  ',' ')\n",
      "        return s\n",
      "\n",
      "clean_dict = {'&AGRAVE;':'A', '&OCIRC;':'O', '&EUML;':'E', '&#203;':'E','&IUML;':'I','&#212;':'O','&#201;':'E', 'INST ': 'INSTITUTE ','&#200;':'E','&EGRAVE;':'E', '&#233;':'E','&EACUTE;':'E','&AMP;':'&', 'INST. ':'INSTITUTE ','ST.':'SAINT', '\\\\XC3\\\\XA8':'E', 'COL.':'COLLEGE', 'COLL.':'COLLEGE','UNIV.':'UNIVERSITY','ONT.':'ONTARIO ', 'THEO.':'THEOLOGICAL' ,'&NDASH;':'-'}    \n",
      "\n",
      "def first_pass_clean(s):\n",
      "    s = deabbreviate(s.upper())\n",
      "    for bad,good in clean_dict.items():\n",
      "        s = s.replace(bad.upper(), good.upper()).upper()\n",
      "    return s\n",
      "\n",
      "def remove_links(s):\n",
      "    s = re.sub(r'<A HREF=.*?>','',s)\n",
      "    s = s.replace('</A>','')\n",
      "    return s.strip()\n",
      "    \n",
      "def clean_employer(s):\n",
      "    s = s.upper().strip()\n",
      "    s = remove_links(s)\n",
      "    #if 'HTML' in s:\n",
      "    #    s = s[s.index('>')+1:] \n",
      "    s = first_pass_clean(s)\n",
      "    \n",
      "    if 'ART ' in s and '& DESIGN' in s:\n",
      "        return 'OCAD'\n",
      "    if 'QUEEN\\'S' in s and ('THEOLOGICAL' in s or 'RELIGION' in s):\n",
      "        return 'QUEEN\\'S SCHOOL OF RELIGION'\n",
      "    if 'SAINT PAUL' in s:\n",
      "        return 'SAINT PAUL'\n",
      "    if 'OTTAWA' in s:\n",
      "        return 'OTTAWA'\n",
      "    if 'SUDBURY' in s:\n",
      "        return 'LAURENTIAN'\n",
      "    if 'CONTACT NORTH' in s:\n",
      "        return 'CONTACT NORTH'\n",
      "    if 'HEARST' in s:\n",
      "        return 'HEARST'\n",
      "    return s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deabbreviate(r'University of Ontario <abbr title=\"Institute\">Inst.</abbr> of <abbr title=\"Technology\">Tech</abbr>.'.upper())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'UNIVERSITY OF ONTARIO INSTITUTE OF TECHNOLOGY '"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.employer = df.employer.apply(clean_employer)\n",
      "print(np.unique(df.employer))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['ALGOMA UNIVERSITY' 'ALGOMA UNIVERSITY COLLEGE'\n",
        " 'BRESCIA UNIVERSITY COLLEGE' 'BROCK' 'BROCK UNIVERSITY' 'CARLETON'\n",
        " 'CARLETON UNIVERSITY' 'CONTACT NORTH' 'GUELPH' 'HEARST'\n",
        " 'HUNTINGTON UNIVERSITY' 'HURON UNIVERSITY COLLEGE'\n",
        " \"KING'S UNIVERSITY COLLEGE\" 'LAKEHEAD' 'LAKEHEAD UNIVERSITY' 'LAURENTIAN'\n",
        " 'LAURENTIAN UNIVERSITY' 'MCMASTER' 'MCMASTER DIVINITY COLLEGE'\n",
        " 'MCMASTER UNIVERSITY' 'NIPISSING' 'NIPISSING UNIVERSITY'\n",
        " 'NORTHERN ONTARIO SCHOOL OF MEDICINE' 'OCAD'\n",
        " 'ONTARIO COLLEGEOF ARTS & DESIGN' 'OTTAWA' \"QUEEN'S\"\n",
        " \"QUEEN'S SCHOOL OF RELIGION\" \"QUEEN'S UNIVERSITY\" 'RYERSON POLYTECHNIC'\n",
        " 'RYERSON POLYTECHNIC UNIVERSITY' 'RYERSON UNIVERSITY'\n",
        " 'SAINT MICHAELS COLLEGE' 'SAINT PAUL' \"SAINT PETER'S SEMINARY\"\n",
        " 'THORNELOE UNIVERSITY' 'TORONTO' 'TRENT' 'TRENT UNIVERSITY'\n",
        " 'TRINITY COLLEGE' 'UNIVERSITY OF GUELPH'\n",
        " 'UNIVERSITY OF ONTARIO INSTITUTE OF TECHNOLOGY'\n",
        " 'UNIVERSITY OF ONTARIO INSTITUTE OF TECHNOLOGY '\n",
        " \"UNIVERSITY OF SAINT MICHAEL'S COLLEGE\" 'UNIVERSITY OF TORONTO'\n",
        " 'UNIVERSITY OF WATERLOO' 'UNIVERSITY OF WESTERN ONTARIO'\n",
        " 'UNIVERSITY OF WINDSOR' 'VICTORIA UNIVERSITY' 'WATERLOO'\n",
        " 'WESTERN ONTARIO ' 'WILFRID LAURIER' 'WILFRID LAURIER UNIVERSITY'\n",
        " 'WINDSOR' 'YORK' 'YORK UNIVERSITY']\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's better, but some duplicates remain - especially pairs of the form (x, UNIVERSITY OF x) or (x, x UNIVERSITY)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.employer = df.employer.str.replace('UNIVERSITY OF ','').apply(lambda s: s[:s.index(' UNIVERSITY')].strip() if s.endswith(' UNIVERSITY') else s.strip())\n",
      "dupe_dict = {'ALGOMA UNIVERSITY COLLEGE':'ALGOMA','KING\\'S COLLEGE':'KING\\'S UNIVERSITY COLLEGE',\n",
      "             'ONTARIO COLLEGEOF ARTS & DESIGN':'OCAD','SAINT MICHAELS COLLEGE':'SAINT MICHAEL\\'S COLLEGE',\n",
      "             'RYERSON POLYTECHNIC':'RYERSON', 'QUEEN\\'S THEOLOGICAL COLLEGE, QUEEN\\'S':'QUEEN\\'S SCHOOL OF RELIGION', 'UNIVERSITE DE HEARST':'HEARST'}\n",
      "df.replace(dupe_dict,inplace=True)\n",
      "print(np.unique(df.employer))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['ALGOMA' 'BRESCIA UNIVERSITY COLLEGE' 'BROCK' 'CARLETON' 'CONTACT NORTH'\n",
        " 'GUELPH' 'HEARST' 'HUNTINGTON' 'HURON UNIVERSITY COLLEGE'\n",
        " \"KING'S UNIVERSITY COLLEGE\" 'LAKEHEAD' 'LAURENTIAN' 'MCMASTER'\n",
        " 'MCMASTER DIVINITY COLLEGE' 'NIPISSING'\n",
        " 'NORTHERN ONTARIO SCHOOL OF MEDICINE' 'OCAD'\n",
        " 'ONTARIO INSTITUTE OF TECHNOLOGY' 'OTTAWA' \"QUEEN'S\"\n",
        " \"QUEEN'S SCHOOL OF RELIGION\" 'RYERSON' \"SAINT MICHAEL'S COLLEGE\"\n",
        " 'SAINT PAUL' \"SAINT PETER'S SEMINARY\" 'THORNELOE' 'TORONTO' 'TRENT'\n",
        " 'TRINITY COLLEGE' 'VICTORIA' 'WATERLOO' 'WESTERN ONTARIO'\n",
        " 'WILFRID LAURIER' 'WINDSOR' 'YORK']\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in ['surname','given_name']:\n",
      "    df[c] = df[c].apply(first_pass_clean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll do a first-pass clean of the positions, too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.position = df.position.apply(first_pass_clean)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of the names, amusingly, have been tagged with inappropriate acronyms:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(df[df.surname.str.contains('ACRONYM')].head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       employer                                            surname given_name  \\\n",
        "55794   TORONTO   SEV'<ACRONYM TITLE=\"EMERGENCY ROOM\">ER</ACRONYM>      AYSAN   \n",
        "57637      YORK  <ACRONYM TITLE=\"CHIEF ADMINISTRATIVE OFFICER\">...    MELANIE   \n",
        "67293    OTTAWA  PA<ACRONYM TITLE=\"CHIEF INFORMATION OFFICER\">C...   DAVID M.   \n",
        "67325    OTTAWA  SAAT<ACRONYM TITLE=\"CHIEF INFORMATION OFFICER\"...      MURAT   \n",
        "68904  WATERLOO  DICIC<ACRONYM TITLE=\"CHIEF INFORMATION OFFICER...  VICTOR F.   \n",
        "\n",
        "                                         position     salary  benefits  year  \n",
        "55794  PROFESSOR SOCIOLOGY/SPECIAL ADVISOR EQUITY  106212.17    307.56  2006  \n",
        "57637                         ASSOCIATE PROFESSOR  153443.24   1113.32  2006  \n",
        "67293                     PROFESSEUR - PROFESSOR   106565.00     84.00  2004  \n",
        "67325                     PROFESSEUR - PROFESSOR   116380.00     84.00  2004  \n",
        "68904                               DIRECTOR, ICR  117476.24    356.22  2004  \n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's get rid of those."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_acronyms(s):\n",
      "    s = re.sub(r'<ACRONYM TITLE=\".*?\">','',s)\n",
      "    s = s.replace('</ACRONYM>','')\n",
      "    return s.strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in ['surname','given_name']:\n",
      "    df[c] = df[c].apply(remove_acronyms).apply(remove_links).str.strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a lot of things we could do with the \"position\" column &mdash; standardizing titles, extracting information about departments, etc. &mdash; but for now we'll just strip out a few carriage returns that are the obstruction to saving this thing as a CSV:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df.position.str.contains('\\r')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>employer</th>\n",
        "      <th>surname</th>\n",
        "      <th>given_name</th>\n",
        "      <th>position</th>\n",
        "      <th>salary</th>\n",
        "      <th>benefits</th>\n",
        "      <th>year</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>43546</th>\n",
        "      <td> QUEEN'S</td>\n",
        "      <td>   LEGGETT</td>\n",
        "      <td>    WILLIAM</td>\n",
        "      <td>  PRINCIPAL &amp; VICE CHANCELLOR &amp; PROF BIOL\\r</td>\n",
        "      <td> 208979.74</td>\n",
        "      <td> 961.07</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43552</th>\n",
        "      <td> TORONTO</td>\n",
        "      <td>     CHING</td>\n",
        "      <td>      JULIA</td>\n",
        "      <td>   PROF PHIL, RLGN &amp; E.A. ST &amp; RC&amp;EYL CHR\\r</td>\n",
        "      <td> 123235.55</td>\n",
        "      <td> 543.36</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>43557</th>\n",
        "      <td> TORONTO</td>\n",
        "      <td> GRIFFITHS</td>\n",
        "      <td> FRANKLYN J</td>\n",
        "      <td> PROF, POL SC &amp; G.I. CHR IN PC &amp; CON STUD\\r</td>\n",
        "      <td> 110622.00</td>\n",
        "      <td> 462.42</td>\n",
        "      <td> 1999</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "      employer    surname  given_name  \\\n",
        "43546  QUEEN'S    LEGGETT     WILLIAM   \n",
        "43552  TORONTO      CHING       JULIA   \n",
        "43557  TORONTO  GRIFFITHS  FRANKLYN J   \n",
        "\n",
        "                                         position     salary  benefits  year  \n",
        "43546   PRINCIPAL & VICE CHANCELLOR & PROF BIOL\\r  208979.74    961.07  1999  \n",
        "43552    PROF PHIL, RLGN & E.A. ST & RC&EYL CHR\\r  123235.55    543.36  1999  \n",
        "43557  PROF, POL SC & G.I. CHR IN PC & CON STUD\\r  110622.00    462.42  1999  "
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.position = df.position.str.replace('\\r','')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More stuff to finish"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It only occurred to me now that a lot of the duplicate-hunting we've done already could be automated, or at least efficiently guided, using string metrics like the <a href=\"http://en.wikipedia.org/wiki/Levenshtein_distance\">Levenshtein distance</a> and the <a href=\"http://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\">Jaro(-Winkler) distance</a>. (The latter is not technically a <a href=\"http://en.wikipedia.org/wiki/Metric_(mathematics)\">metric</a> in the mathematical sense of the term.)\n",
      "\n",
      "These are implemented in the packages <tt><a href=\"https://pypi.python.org/pypi/python-Levenshtein/0.12.0\">python-Levenshtein</a></tt> and <tt><a href=\"https://pypi.python.org/pypi/jellyfish/0.4.0\">jellyfish</a></tt>, among others.\n",
      "\n",
      "Here's a paper that analyses the complexity and appropriateness of these methods for different comparison tasks:\n",
      "\n",
      "<a href=\"http://cs.anu.edu.au/~Peter.Christen/publications/tr-cs-06-02.pdf\">A Comparison of Personal Name Matching: Techniques and Practical Issues</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# !pip install Levenshtein\n",
      "# !pip install jellyfish\n",
      "import Levenshtein, jellyfish\n",
      "print(Levenshtein.distance('gumshoe', 'elephantitis'))\n",
      "print(Levenshtein.distance('gumshoe','gumshieo'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11\n",
        "2\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's now use this to find some more typos and other duplicates (e.g. hyphens replaced by spaces in compound surnames). Seeing as there may be different people whose last names are spelled very similarly, let's work with full names.\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['full_name'] = df.surname + ', '+df.given_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We'll make the assumption that if two people with similar names appear as employees of the same organization in the same year, they are indeed distinct people. This means that in order to detect typos and variations, we only need to look at pairs of rows that have distinct years."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g = df.groupby('year')\n",
      "names_by_year = g.agg(lambda s:[np.unique(s)]).full_name.apply(lambda l:l[0])\n",
      "print(names_by_year.head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "year\n",
        "1997    [ADAM, G. STUART, AITKEN, JOHAN L, AIVAZIAN, V...\n",
        "1998    [ABRAMSON, MORTON, ACKERMANN, UWE, ADAM, G. ST...\n",
        "1999    [BERGER, CARL, CHING, JULIA, COLE, SUSAN P, FA...\n",
        "2000    [BAIRD, MICHAEL, BERGER, CARL, COLE, SUSAN P, ...\n",
        "2001    [BAILEY, RICHARD, BAIRD, MICHAEL, BERGER, CARL...\n",
        "Name: full_name, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a lot of names that contain initials. We should probably deal with these separately."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def has_initial(name):\n",
      "    if '.' in name: return True\n",
      "    for token in name.split():\n",
      "        if len(token) == 1:\n",
      "            return True\n",
      "    return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = ['MICHAEL J. FOX', 'ALFRED E NEUMAN', 'DAVID BYRNE']\n",
      "for name in names: print name, has_initial(name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MICHAEL J. FOX True\n",
        "ALFRED E NEUMAN True\n",
        "DAVID BYRNE False\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "initialed_names_by_year = names_by_year.apply(lambda name_list: [name for name in name_list if has_initial(name)])\n",
      "complete_names_by_year = names_by_year.apply(lambda name_list: [name for name in name_list if not has_initial(name)])\n",
      "print(initialed_names_by_year.head())\n",
      "\n",
      "print(complete_names_by_year.head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "year\n",
        "1997    [ADAM, G. STUART, AITKEN, JOHAN L, AKCOGLU, MU...\n",
        "1998    [ADAM, G. STUART, ADAMOWSKI, THOMAS H, ADAMS, ...\n",
        "1999    [COLE, SUSAN P, GRIFFITHS, FRANKLYN J, WALKER,...\n",
        "2000                     [COLE, SUSAN P, WALKER, DAVID M]\n",
        "2001               [COLE, SUSAN P, GRIFFITHS, FRANKLYN J]\n",
        "Name: full_name, dtype: object\n",
        "year\n",
        "1997    [AIVAZIAN, VAROUJ, ALBERTI, PETER, ALPER, HOWA...\n",
        "1998    [ABRAMSON, MORTON, ACKERMANN, UWE, ADAMS, SUSA...\n",
        "1999    [BERGER, CARL, CHING, JULIA, FALKENHEIM, VICTO...\n",
        "2000    [BAIRD, MICHAEL, BERGER, CARL, COYTE, PETER, D...\n",
        "2001    [BAILEY, RICHARD, BAIRD, MICHAEL, BERGER, CARL...\n",
        "Name: full_name, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "to do later"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from itertools import product\n",
      "\n",
      "def pairwise_distances(metric, x1,year1,x2,year2):\n",
      "    for s,t in product(x1,x2):\n",
      "        d = metric(s,t)\n",
      "        if 0 < d < 4:\n",
      "            yield (s, year1, t, year2, d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Between Levenshtein and Jaro, which is faster? And for each, which of the two implementations is faster?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pairwise_distance_dfs = []\n",
      "years = np.unique(df.year)\n",
      "year_pairs = [(year1,year2) for year1, year2 in product(years,years) if year1 < year2]\n",
      "year1 = 1999\n",
      "year2 = 2010\n",
      "for metric in [Levenshtein.distance, Levenshtein.jaro, jellyfish.levenshtein_distance, jellyfish.jaro_distance]:\n",
      "    print metric\n",
      "    %timeit sdf = pd.DataFrame(list(pairwise_distances(metric, names_by_year[year1],year1,names_by_year[year2],year2)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<built-in function distance>\n",
        "1 loops, best of 3: 211 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<built-in function jaro>\n",
        "1 loops, best of 3: 357 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<built-in function levenshtein_distance>\n",
        "1 loops, best of 3: 335 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<built-in function jaro_distance>\n",
        "1 loops, best of 3: 464 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hm. Jaro is theoretically faster than Levenshtein since its complexity is linear in string length (see section 5 of <a href=\"http://cs.anu.edu.au/~Peter.Christen/publications/tr-cs-06-02.pdf\">this paper</a>). But the implementation of Levenshtein distance in the library <tt>Levenshtein</tt> seems to be quite highly optimized."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''for year1, year2 in year_pairs:\n",
      "    pairwise_distance_dfs.append(pd.DataFrame(list(pairwise_Levenshtein(names_by_year[year1],year1,names_by_year[year2],year2))))\n",
      "\n",
      "pairwise_distance_df = pd.concat(pairwise_distance_dfs)'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "'for year1, year2 in year_pairs:\\n    pairwise_distance_dfs.append(pd.DataFrame(list(pairwise_Levenshtein(names_by_year[year1],year1,names_by_year[year2],year2))))\\n\\npairwise_distance_df = pd.concat(pairwise_distance_dfs)'"
       ]
      }
     ],
     "prompt_number": 28
    }
   ],
   "metadata": {}
  }
 ]
}
